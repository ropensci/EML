
The future belongs to those who can leverage existing data and provide reusable data.  

1. Reuse is essential
2. Reuse requires good metadata standards
3. reml provides an easy way to utilize the Ecological Metadata Language to generate, access, and publish data.  

Data in ecology and evolutionary biology research collected for a
particular purpose can often prove valuable to an entirely different
line of research. One study may collect morphometric measurements of
coral reef fish taken to understand their evolution, while another
reuses only the species names and geographic locations of the samples,
along with other data, to aid the design of marine reserves.  Such reuse
is fundamental to much of our research, and yet it is often difficult
or laborious to discover and obtain. The publications are the only
documentation of what data is available.  The distribution and discovery
of publications is geared towards reaching audience interested in common
set of questions, not a common set of data. Even within a subdispline,
re-use of data is often laborious or impossible due to lack of data or
sufficient documentation of the data.


Vertically intergrated data repositories such as Genbank, GBIF [Canhos 2004],
or TreeBase [Morell 1996] provide one route to addressing the challenges 
of data integration.  These data warehouses provide all there data in a common 
structure that can usually be queried through a web interface. This makes it
relatively easy to discover available data and access it in a consistent and
predictable format.  However, such utility comes at a cost.  This approach
discards the original data model, preserving only the data that can be shoehorned
into a common data standard. 

<!-- is "data model" more confusing than "data format"? -->

These challenges have long been recognized and broadly accepted that
they can be best addressed through establishing and using appropriate
metadata [Michener 1997]. In this approach it is the metadata, rather than
the data itself, that conforms to a standard.  The Knowledge Network for
Biocomplexity (KNB) is one example of a metadata-based ecological data 
repository [Berkley 2001], [KNB].  The metadata approach preserves the original data
model from the collecting study. Rather than requiring that the raw data
be preserved in a standard format -- standard file types, standard column headings, 
standard date formats, missing value formats, etc etc, -- the metadata standard
approach provides a consisent way to document whatever data model the researchers
use.  In principle, this approach is both more powerful than vertical integration, 
(as the full context of the data is preserved), and easier to implement for both
researcher and repository (as the researcher does not to to convert data to 
the format required by the repository, and very heterogenous data models can be 
stored and searched for in a single system).   [Jones 2006] provides
an excellent explanation and comparison of these approaches.  

Unfortunately, adoption of these metadata standards for annotating research
data has been limited, owing to both technological and social challenges 
involved [Reichman 2011].


Things to discuss:

*  It's not just a problem of sharing culture 
* Sharing is not effective: close competitors can scoop you, but broader reach can't be realized without good metadata 
* [Strasser survey showing lagging data management practices]
* [Stodden survey showing effort in curating data is a barrier]

Consequently ecological
data reuse remains difficult and haphazard. 


Widely adopted computing environments such as the R statistical sofware
provide a key opportunity to increase adoption of metadata standards. 



Methods in Ecology and Evolution has published XXX application notes or articles presenting new software packages.  XXX of them are R packages.  

[Reichman 2011]: http://dx.doi.org/10.1126/science.1197962
[Jones 2006]: http://dx.doi.org/10.1146/annurev.ecolsys.37.091305.110031
[KNB]: http://knb.ecoinformatics.org
[Berkley 2001]: http://dx.doi.org/10.1109/4236.957896
[Michener 1997]: http://dx.doi.org/10.1890/1051-0761(1997)007[0330:NMFTES]2.0.CO;2
[Morell 1996]: http://dx.doi.org/10.1126/science.273.5275.569
[Canhos 2004]: https://journals.ku.edu/index.php/jbi/article/viewArticle/3 
[Michener 2006]: http://dx.doi.org/10.1016/j.ecoinf.2005.08.004
[Michener 2012]: http://dx.doi.org/10.1016/j.tree.2011.11.016

1. Commonly used data structures in R provide basic metadata automatically
2. We can more easily avoid redundant metadata entry 
3. Automate quality control checks
4. Publish
5. Arbitrarily complex search 
6. Building a synthesis platform


### Automatic metadata detection

Not sure this counts as a section - but we can automatically detect at least the difference between numeric and character data, factors, ordered factors, etc.  

### Reusing fields

- Examples of filling in contact information, etc using `eml$set`, using an existing EML file as a template, and using an external yaml file.  

- Similar example for `column_metadata` and `unit_metadata` based on an existing EML file (just using `eml_read`).  

### Automatic Quality Control checks

<!-- Not sure if we'll actually have/need to have all this in place for this paper?  -->
Examples of validation against schema.  Examples checking md5sums on files or other corruption checks?  Examples checking species names (taxize?)

### Publish data

Examples of commands for publishing EML files to external repositories.  

### Complex search queries

Illustrate how to query for data  

### A synthesis platform

Illustrate a basic example of synthesis.  While arbitrary synthesis will require semantics, a lab could store their data in EML format and build up there own library of common scripts to extract the data they need. As a lab database grows, the same queries can continue to deliver more data.  By scripting the data access, analyses can be automatically updated as the data set grows.   

Consider simple example in regression between different morphological characters of species, or such.  


## Challenges

Completely automated data integration will require rich semantic information. Consider the simple example of combining the two data tables shown in Figure 2.  

<!-- Example illustrating the need for semantics to resolve differences -->


### Implementation and architecture

The `reml` package is built for the Ecological Markup Language schema, [version 2.1.1], using the R software environment and the XML package for parsing and generating XML [Temple Lang 2013, XML]. 

<!-- Possibly cite all dependencies and suggests from the DESCRIPTION --> 
<!-- Reference any installation and configuration instructions necessary (e.g. API credentials for figshare) -->

[version 2.1.1]: http://knb.ecoinformatics.org/software/eml/eml-2.1.1
[Temple Lang 2013, XML]: http://cran.r-project.org/web/packages/XML/

### Quality control

The `reml` package can perform three levels of validation on EML files written from or read into R: validating the XML, validating against the EML 2.1.1 Schema, and performing

Several mechanisms are in place to evaluate the quality of the `reml` package functions themselves.  In addition to the examples from the documentation and the automated package checks provided for the R system, the `reml` package includes a complete test suite using the testthat package [Wickham 2011].  

[Wickham 2011]: http://vita.had.co.nz/papers/testthat.html

### Software reuse and support

The `reml` package is available through the CRAN repository under a CC0 license. At the time of writing, the current version is `r packageDescription("reml", fields="Version")`. The current development branch can be found on Github at [https://github.com/ropensci/reml].  See the NEWS file for changes in recent versions. Users are encouraged to submit bug reports or feature requests in the issues log.  Contact ropensci-discuss@googlegroups.com or the package maintainer for help. 

There are many promising directions for further development of the `reml` package.  The project's Milestones page provides a list of steps currently planned or under consideration.  In particular, these milestones include increased support for interactive mode of entering data (wizards), and support for integration of semantics defined through the Web Ontology language (OWL), as discussed in the Challenges section.  



### Acknowledgements

This project was supported in part by a grant from the Alfred P Sloan Foundation (CB and KR), NSF Grant DBI-1306697 (CB), ... `reml` is part of the rOpenSci project, [http://ropensci.org].  




OLD OUTLINE
----------------------------------------------------------------------------------------------



It's all metadata.  

Share 
Metadata
raw data
formats: file formats, table formats, cell formats 
good null values
easy to combine (context data)
quality control
repository
license









Abstract

1. Recording good metadata is at the heart of effective data synthesis and reuse
2. 

Vertically integrated repositories vs metadata driven repositories.  


Data synthesis


## Why EML?


But specifying metadata is typically onerous, time-consuming and error prone. 

Such definitions are also not machine readable.  

Or at least, it doesn't have to be that way.  We just need better tools.  


## Why REML?

* The Ecological Metadata Language (EML) has been around for a while now, but has so far seen limited use.  

* R is a widely adopted among the community, many researchers already familiar with reading and writing data from R.

* R provides a rich set of data types and constructs that can be mapped into EML (e.g. integers, floats, ordered/nominal factors, character strings)



### Current state of EML

* Generation of EML is limited.  e.g. to LTER centers with informatics support. 
* Applications of existing EML more limited still (?)  

* Software to work with EML is limited to tools with low adoption rates across the community (e.g. Kepler). 

 Researchers are isolated from the metadata encoding, instead providing plain-text descriptions in MS Word documents.  Allows for low barrier of entry but also makes a barrier to richer encoding.  



### Promise of REML


### Getting Started: A minimal example.  

Imagine we are working with a `data.frame` in R analgous to Table 1.

<!--Writing a data.frame into EML -->


Writing this table into EML 

### Authoring tools

### Parsing tools

### Publishing tools


